{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. eng-fra.txt download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-03-10 02:31:13--  https://raw.githubusercontent.com/L1aoXingyu/seq2seq-translation/master/data/eng-fra.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 9541158 (9.1M) [text/plain]\n",
      "Saving to: 'eng-fra.txt.1'\n",
      "\n",
      "eng-fra.txt.1       100%[===================>]   9.10M  6.48MB/s    in 1.4s    \n",
      "\n",
      "2023-03-10 02:31:15 (6.48 MB/s) - 'eng-fra.txt.1' saved [9541158/9541158]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/L1aoXingyu/seq2seq-translation/master/data/eng-fra.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing\n",
    "1. 필요한 없는 부호 또는 물음표, 느낌표 모으기\n",
    "2. 필요한 없는 부호 ' '로 바꿔주기\n",
    "3. 영어문장 불어문장으로 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['have', 'you', 'had', 'dinner']\n",
      "['avez', 'vous', 'déjà', 'diné']\n"
     ]
    }
   ],
   "source": [
    "eng_sen = \"Have you had dinner?\"\n",
    "fra_sen = \"Avez-vous déjà diné?\"\n",
    "\n",
    "eng_sen = eng_sen.replace('-',' ').replace('?',' ')\n",
    "fra_sen = fra_sen.replace('-',' ').replace('?',' ')\n",
    "\n",
    "print(eng_sen.lower().split())\n",
    "print(fra_sen.lower().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '\"', '$', '%', '&', '(', ')', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '~', '\\xa0', '«', '\\xad', '»', '\\u2009', '\\u200b', '‐', '–', '‘', '’', '…', '\\u202f', '‽', '₂', '€', '\\u3000']\n",
      "‘)~5/ ,0!%\"»-­　&‐6?–‽9₂ 13(+​… .7:824€;«’$\n"
     ]
    }
   ],
   "source": [
    "with open('eng-fra.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "specials = set(text.lower()) - set('abcdefghijklmnopqrstuvwxyzàâçèéêëîïòôöùúûœас\\t\\n\\' ')\n",
    "print(sorted(specials))\n",
    "print(''.join(specials))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go.\tVa !\n",
      "Run!\tCours !\n",
      "Run!\tCourez !\n",
      "Wow!\tÇa alors !\n",
      "Fire!\tAu feu !\n",
      "Help!\tÀ l'aide !\n",
      "Jump.\tSaute.\n",
      "Sto\n"
     ]
    }
   ],
   "source": [
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go \tva  \n",
      "run \tcours  \n",
      "run \tcourez  \n",
      "wow \tça alors  \n",
      "fire \tau feu  \n",
      "help \tà l'aide  \n",
      "jump \tsaute \n",
      "sto\n"
     ]
    }
   ],
   "source": [
    "text = text.lower()\n",
    "text_alpha = text\n",
    "for s in specials:\n",
    "    text_alpha = text_alpha.replace(s, ' ')\n",
    "\n",
    "print(text_alpha[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['go ', 'va  '], ['run ', 'cours  '], ['run ', 'courez  '], ['wow ', 'ça alors  '], ['fire ', 'au feu  '], ['help ', \"à l'aide  \"], ['jump ', 'saute '], ['stop ', 'ça suffit  '], ['stop ', 'stop  '], ['stop ', 'arrête toi  ']]\n",
      "135843\n"
     ]
    }
   ],
   "source": [
    "lines = [line.split('\\t') for line in text_alpha.split('\\n')]\n",
    "print(lines[:10])\n",
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "lines = lines[:50000]\n",
    "random.shuffle(lines)\n",
    "eng_sentence, fra_sentence = zip(*lines)\n",
    "eng_sentence = [s.strip() for s in eng_sentence]\n",
    "fra_sentence = [s.strip() for s in fra_sentence]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-1. Implementation for seq2seq (Character level)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fra_sentence = [f'\\t{s}\\n' for s in fra_sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 73\n",
      "[' ', \"'\", 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'é'] 29\n",
      "['\\t', '\\n', ' ', \"'\", 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'à', 'â', 'ç', 'è', 'é', 'ê', 'ë', 'î', 'ï', 'ô', 'ù', 'û', 'œ', 'с'] 44\n"
     ]
    }
   ],
   "source": [
    "eng_char = sorted(set(''.join(eng_sentence)))\n",
    "fra_char = sorted(set(''.join(fra_sentence)))\n",
    "eng_length = max(map(len,eng_sentence))\n",
    "fra_length = max(map(len,fra_sentence))\n",
    "print(eng_length,fra_length)\n",
    "print(eng_char,len(eng_char))\n",
    "print(fra_char,len(fra_char))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. set length same using padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, \"'\": 1, 'a': 2, 'b': 3, 'c': 4, 'd': 5, 'e': 6, 'f': 7, 'g': 8, 'h': 9, 'i': 10, 'j': 11, 'k': 12, 'l': 13, 'm': 14, 'n': 15, 'o': 16, 'p': 17, 'q': 18, 'r': 19, 's': 20, 't': 21, 'u': 22, 'v': 23, 'w': 24, 'x': 25, 'y': 26, 'z': 27, 'é': 28}\n",
      "{'\\t': 0, '\\n': 1, ' ': 2, \"'\": 3, 'a': 4, 'b': 5, 'c': 6, 'd': 7, 'e': 8, 'f': 9, 'g': 10, 'h': 11, 'i': 12, 'j': 13, 'k': 14, 'l': 15, 'm': 16, 'n': 17, 'o': 18, 'p': 19, 'q': 20, 'r': 21, 's': 22, 't': 23, 'u': 24, 'v': 25, 'w': 26, 'x': 27, 'y': 28, 'z': 29, 'à': 30, 'â': 31, 'ç': 32, 'è': 33, 'é': 34, 'ê': 35, 'ë': 36, 'î': 37, 'ï': 38, 'ô': 39, 'ù': 40, 'û': 41, 'œ': 42, 'с': 43}\n"
     ]
    }
   ],
   "source": [
    "eng_tok = {c: i for i,c in enumerate(eng_char)}\n",
    "fra_tok = {c: i for i,c in enumerate(fra_char)}\n",
    "\n",
    "print(eng_tok)\n",
    "print(fra_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_pad = [list(eng.ljust(eng_length)) for eng in eng_sentence]\n",
    "fra_pad = [list(fra.ljust(fra_length)) for fra in fra_sentence]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. change token into idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "eng_idx = np.array([list(map(eng_tok.get, eng)) for eng in eng_pad])\n",
    "fra_idx = np.array([list(map(fra_tok.get, fra)) for fra in fra_pad])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 24)\n",
      "(50000, 73)\n"
     ]
    }
   ],
   "source": [
    "print(eng_idx.shape)\n",
    "print(fra_idx.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. change the idx value into one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 24, 29)\n",
      "(50000, 73, 44)\n"
     ]
    }
   ],
   "source": [
    "eng_onehot = np.array([np.eye(len(eng_char))[eng] for eng in eng_idx])\n",
    "fra_onehot = np.array([np.eye(len(fra_char))[fra] for fra in fra_idx])\n",
    "print(eng_onehot.shape)\n",
    "print(fra_onehot.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### implement Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement Encoder with class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 256])\n",
      "(10, 73, 44)\n"
     ]
    }
   ],
   "source": [
    "encoder = nn.GRU(29, 256, batch_first= True)\n",
    "output, hidden = encoder(torch.FloatTensor(eng_onehot[:10,:,:]))\n",
    "\n",
    "print(hidden.shape)\n",
    "\n",
    "# decoder = nn.Sequential(\n",
    "#     nn.GRU(44, 256, batch_first= True),\n",
    "#     nn.Linear(256, 44),\n",
    "#     nn.LogSoftmax(dim=1)\n",
    "# )\n",
    "decoder = nn.GRU(44, 256, batch_first= True)\n",
    "print(fra_onehot[:10].shape)\n",
    "output, hidden = decoder(torch.FloatTensor(fra_onehot[:10]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers):\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRU(self.input_dim, self.hidden_dim, num_layers= self.num_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs, hidden = self.gru(x)\n",
    "        return outputs, hidden"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement Decoder with class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, hidden_dim, input_dim, num_layers):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.gru = nn.GRU(self.input_dim, self.hidden_dim, num_layers= self.num_layers)\n",
    "        self.out = nn.Linear(self.hidden_dim, output_dim)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "    def forward(self, input, hidden):\n",
    "        input = input(1, -1)\n",
    "        output, hidden = self.gru(input, hidden)\n",
    "        prediction = self.softmax(self.out(output[0]))\n",
    "        return prediction, hidden"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement seq2seq using `Encoder` class and `Decoder` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
