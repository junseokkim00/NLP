{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. eng-fra.txt download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-03-09 04:02:30--  https://raw.githubusercontent.com/L1aoXingyu/seq2seq-translation/master/data/eng-fra.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 9541158 (9.1M) [text/plain]\n",
      "Saving to: 'eng-fra.txt'\n",
      "\n",
      "eng-fra.txt         100%[===================>]   9.10M  6.64MB/s    in 1.4s    \n",
      "\n",
      "2023-03-09 04:02:32 (6.64 MB/s) - 'eng-fra.txt' saved [9541158/9541158]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/L1aoXingyu/seq2seq-translation/master/data/eng-fra.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing\n",
    "1. 필요한 없는 부호 또는 물음표, 느낌표 모으기\n",
    "2. 필요한 없는 부호 ' '로 바꿔주기\n",
    "3. 영어문장 불어문장으로 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['have', 'you', 'had', 'dinner']\n",
      "['avez', 'vous', 'déjà', 'diné']\n"
     ]
    }
   ],
   "source": [
    "eng_sen = \"Have you had dinner?\"\n",
    "fra_sen = \"Avez-vous déjà diné?\"\n",
    "\n",
    "eng_sen = eng_sen.replace('-',' ').replace('?',' ')\n",
    "fra_sen = fra_sen.replace('-',' ').replace('?',' ')\n",
    "\n",
    "print(eng_sen.lower().split())\n",
    "print(fra_sen.lower().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '\"', '$', '%', '&', '(', ')', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '~', '\\xa0', '«', '\\xad', '»', '\\u2009', '\\u200b', '‐', '–', '‘', '’', '…', '\\u202f', '‽', '₂', '€', '\\u3000']\n",
      "3\"‽&?+…1/4! )‘ 　₂%78~(’€«;,-5»​$96–.­02‐ :\n"
     ]
    }
   ],
   "source": [
    "with open('eng-fra.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "specials = set(text.lower()) - set('abcdefghijklmnopqrstuvwxyzàâçèéêëîïòôöùúûœас\\t\\n\\' ')\n",
    "print(sorted(specials))\n",
    "print(''.join(specials))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go.\tVa !\n",
      "Run!\tCours !\n",
      "Run!\tCourez !\n",
      "Wow!\tÇa alors !\n",
      "Fire!\tAu feu !\n",
      "Help!\tÀ l'aide !\n",
      "Jump.\tSaute.\n",
      "Sto\n"
     ]
    }
   ],
   "source": [
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go \tva  \n",
      "run \tcours  \n",
      "run \tcourez  \n",
      "wow \tça alors  \n",
      "fire \tau feu  \n",
      "help \tà l'aide  \n",
      "jump \tsaute \n",
      "sto\n"
     ]
    }
   ],
   "source": [
    "text = text.lower()\n",
    "text_alpha = text\n",
    "for s in specials:\n",
    "    text_alpha = text_alpha.replace(s, ' ')\n",
    "\n",
    "print(text_alpha[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['go ', 'va  '], ['run ', 'cours  '], ['run ', 'courez  '], ['wow ', 'ça alors  '], ['fire ', 'au feu  '], ['help ', \"à l'aide  \"], ['jump ', 'saute '], ['stop ', 'ça suffit  '], ['stop ', 'stop  '], ['stop ', 'arrête toi  ']]\n",
      "135843\n"
     ]
    }
   ],
   "source": [
    "lines = [line.split('\\t') for line in text_alpha.split('\\n')]\n",
    "print(lines[:10])\n",
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "lines = lines[:50000]\n",
    "random.shuffle(lines)\n",
    "eng_sentence, fra_sentence = zip(*lines)\n",
    "eng_sentence = [s.strip() for s in eng_sentence]\n",
    "fra_sentence = [s.strip() for s in fra_sentence]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-1. Implementation for seq2seq (Character level)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fra_sentence = [f'\\t{s}\\n' for s in fra_sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 73\n",
      "[' ', \"'\", 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'é'] 29\n",
      "['\\t', '\\n', ' ', \"'\", 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'à', 'â', 'ç', 'è', 'é', 'ê', 'ë', 'î', 'ï', 'ô', 'ù', 'û', 'œ', 'с'] 44\n"
     ]
    }
   ],
   "source": [
    "eng_char = sorted(set(''.join(eng_sentence)))\n",
    "fra_char = sorted(set(''.join(fra_sentence)))\n",
    "eng_length = max(map(len,eng_sentence))\n",
    "fra_length = max(map(len,fra_sentence))\n",
    "print(eng_length,fra_length)\n",
    "print(eng_char,len(eng_char))\n",
    "print(fra_char,len(fra_char))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. set length same using padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, \"'\": 1, 'a': 2, 'b': 3, 'c': 4, 'd': 5, 'e': 6, 'f': 7, 'g': 8, 'h': 9, 'i': 10, 'j': 11, 'k': 12, 'l': 13, 'm': 14, 'n': 15, 'o': 16, 'p': 17, 'q': 18, 'r': 19, 's': 20, 't': 21, 'u': 22, 'v': 23, 'w': 24, 'x': 25, 'y': 26, 'z': 27, 'é': 28}\n",
      "{'\\t': 0, '\\n': 1, ' ': 2, \"'\": 3, 'a': 4, 'b': 5, 'c': 6, 'd': 7, 'e': 8, 'f': 9, 'g': 10, 'h': 11, 'i': 12, 'j': 13, 'k': 14, 'l': 15, 'm': 16, 'n': 17, 'o': 18, 'p': 19, 'q': 20, 'r': 21, 's': 22, 't': 23, 'u': 24, 'v': 25, 'w': 26, 'x': 27, 'y': 28, 'z': 29, 'à': 30, 'â': 31, 'ç': 32, 'è': 33, 'é': 34, 'ê': 35, 'ë': 36, 'î': 37, 'ï': 38, 'ô': 39, 'ù': 40, 'û': 41, 'œ': 42, 'с': 43}\n"
     ]
    }
   ],
   "source": [
    "eng_tok = {c: i for i,c in enumerate(eng_char)}\n",
    "fra_tok = {c: i for i,c in enumerate(fra_char)}\n",
    "\n",
    "print(eng_tok)\n",
    "print(fra_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_pad = [list(eng.ljust(eng_length)) for eng in eng_sentence]\n",
    "fra_pad = [list(fra.ljust(fra_length)) for fra in fra_sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "eng_idx = np.array([list(map(eng_tok.get, eng)) for eng in eng_pad])\n",
    "fra_idx = np.array([list(map(fra_tok.get, fra)) for fra in fra_pad])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 24)\n",
      "(50000, 73)\n"
     ]
    }
   ],
   "source": [
    "print(eng_idx.shape)\n",
    "print(fra_idx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 24, 29)\n",
      "(50000, 73, 44)\n"
     ]
    }
   ],
   "source": [
    "eng_onehot = np.array([np.eye(len(eng_char))[eng] for eng in eng_idx])\n",
    "fra_onehot = np.array([np.eye(len(fra_char))[fra] for fra in fra_idx])\n",
    "print(eng_onehot.shape)\n",
    "print(fra_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
