{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Char RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', 'a', 'e', 'l', 'p']\n"
     ]
    }
   ],
   "source": [
    "input_str = 'apple'\n",
    "label_str = 'pple!'\n",
    "char_vocab = sorted(list(set(input_str+label_str)))\n",
    "print(char_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(char_vocab)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use a `one hot vector` for every character. This means every character is going to have a `vocab_size` size of vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = vocab_size\n",
    "hidden_size = 5\n",
    "output_size = 5\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'!': 0, 'a': 1, 'e': 2, 'l': 3, 'p': 4}\n"
     ]
    }
   ],
   "source": [
    "char_to_index = dict((c,i) for i, c in enumerate(char_vocab))\n",
    "print(char_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '!', 1: 'a', 2: 'e', 3: 'l', 4: 'p'}\n"
     ]
    }
   ],
   "source": [
    "index_to_char={}\n",
    "for key, value in char_to_index.items():\n",
    "    index_to_char[value] = key\n",
    "print(index_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 4, 3, 2]\n",
      "[4, 4, 3, 2, 0]\n"
     ]
    }
   ],
   "source": [
    "x_data = [char_to_index[c] for c in input_str]\n",
    "y_data = [char_to_index[c] for c in label_str]\n",
    "print(x_data)\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_one_hot = [np.eye(vocab_size)[x_data]]\n",
    "# y_data = [np.eye(vocab_size)[y_data]]\n",
    "X = torch.FloatTensor(x_one_hot)\n",
    "Y = torch.LongTensor(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _status = self.rnn(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(input_size, hidden_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "outputs = net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 5])\n"
     ]
    }
   ],
   "source": [
    "print(outputs.view(-1, input_size).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: loss:1.3171494007110596\n",
      "1: loss:1.1435484886169434\n",
      "2: loss:0.9743162393569946\n",
      "3: loss:0.7830328345298767\n",
      "4: loss:0.6111847758293152\n",
      "5: loss:0.473209947347641\n",
      "6: loss:0.35816025733947754\n",
      "7: loss:0.2656562924385071\n",
      "8: loss:0.19771064817905426\n",
      "9: loss:0.14820870757102966\n",
      "10: loss:0.1113034039735794\n",
      "11: loss:0.08416984975337982\n",
      "12: loss:0.06493230164051056\n",
      "13: loss:0.05044865608215332\n",
      "14: loss:0.038754016160964966\n",
      "15: loss:0.029881086200475693\n",
      "16: loss:0.023426655679941177\n",
      "17: loss:0.018636813387274742\n",
      "18: loss:0.014998664148151875\n",
      "19: loss:0.012214486487209797\n",
      "20: loss:0.010073183104395866\n",
      "21: loss:0.008397890254855156\n",
      "22: loss:0.007055474910885096\n",
      "23: loss:0.005970596801489592\n",
      "24: loss:0.0051023224368691444\n",
      "25: loss:0.0044135539792478085\n",
      "26: loss:0.003865160048007965\n",
      "27: loss:0.0034221361856907606\n",
      "28: loss:0.0030574225820600986\n",
      "29: loss:0.0027518807910382748\n",
      "30: loss:0.002491906750947237\n",
      "31: loss:0.002268292475491762\n",
      "32: loss:0.0020741198677569628\n",
      "33: loss:0.0019046490779146552\n",
      "34: loss:0.001755991019308567\n",
      "35: loss:0.0016253947978839278\n",
      "36: loss:0.0015105115016922355\n",
      "37: loss:0.0014094666112214327\n",
      "38: loss:0.00132052693516016\n",
      "39: loss:0.001242291764356196\n",
      "40: loss:0.0011734783183783293\n",
      "41: loss:0.0011129461927339435\n",
      "42: loss:0.001059768139384687\n",
      "43: loss:0.0010130408918485045\n",
      "44: loss:0.0009720750385895371\n",
      "45: loss:0.000935870804823935\n",
      "46: loss:0.0009040000732056797\n",
      "47: loss:0.0008756536990404129\n",
      "48: loss:0.0008504032157361507\n",
      "49: loss:0.0008276055450551212\n",
      "50: loss:0.0008069991017691791\n",
      "51: loss:0.0007881788769736886\n",
      "52: loss:0.0007709069177508354\n",
      "53: loss:0.0007551116868853569\n",
      "54: loss:0.0007405075011774898\n",
      "55: loss:0.0007270228816196322\n",
      "56: loss:0.0007146578864194453\n",
      "57: loss:0.0007031743298284709\n",
      "58: loss:0.0006925245397724211\n",
      "59: loss:0.000682518002577126\n",
      "60: loss:0.0006731784669682384\n",
      "61: loss:0.0006643630331382155\n",
      "62: loss:0.0006560479523614049\n",
      "63: loss:0.0006480664014816284\n",
      "64: loss:0.0006404422456398606\n",
      "65: loss:0.0006331991171464324\n",
      "66: loss:0.0006261466769501567\n",
      "67: loss:0.0006194753805175424\n",
      "68: loss:0.0006129946559667587\n",
      "69: loss:0.000606799847446382\n",
      "70: loss:0.0006008193595334888\n",
      "71: loss:0.0005950771155767143\n",
      "72: loss:0.0005895731737837195\n",
      "73: loss:0.0005842120735906065\n",
      "74: loss:0.0005789939896203578\n",
      "75: loss:0.0005739902262575924\n",
      "76: loss:0.0005690579419024289\n",
      "77: loss:0.0005642924224957824\n",
      "78: loss:0.0005596459959633648\n",
      "79: loss:0.0005550709902308881\n",
      "80: loss:0.0005505674635060132\n",
      "81: loss:0.0005462545086629689\n",
      "82: loss:0.0005419416120275855\n",
      "83: loss:0.0005377477500587702\n",
      "84: loss:0.0005336492322385311\n",
      "85: loss:0.0005295982700772583\n",
      "86: loss:0.0005256665172055364\n",
      "87: loss:0.0005218061851337552\n",
      "88: loss:0.000517945911269635\n",
      "89: loss:0.0005141808651387691\n",
      "90: loss:0.0005105350282974541\n",
      "91: loss:0.0005068890750408173\n",
      "92: loss:0.0005033385241404176\n",
      "93: loss:0.0004997640498913825\n",
      "94: loss:0.0004962849197909236\n",
      "95: loss:0.0004928296548314393\n",
      "96: loss:0.0004894696758128703\n",
      "97: loss:0.00048610963858664036\n",
      "98: loss:0.00048277340829372406\n",
      "99: loss:0.00047958019422367215\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    outputs= net(X)\n",
    "    loss = criterion(outputs.view(-1, 5), Y.view(-1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(\"{}: loss:{}\".format(i, loss))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
